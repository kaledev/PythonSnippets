{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing in Python\n",
    "### LDA vs NMF Topic clustering\n",
    "\n",
    "A quick no-nonsense overview of utilizing LDA (Latent Dirichlet Allocation) vs. NMF (Non-Negative Matrix Factorization) for unsupervised topic clustering problems in NLP.\n",
    "\n",
    "The dataset I'm using is located [here](https://github.com/kaledev/PythonSnippets/tree/master/Datasets/npr.csv), and contains a large set of scraped news-stories from NPR (mostly political).\n",
    "\n",
    "Through these two examples I will categorize each article into one of 8 topics that are defined through LDA/NMF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "\n",
    "Note that for LDA we need to utilize the CountVectorizer instead of TF-IDF as LDA relies on per word-count vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "npr = pd.read_csv('Datasets/npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  In the Washington of 2016, even when the polic...\n",
       "1    Donald Trump has used Twitter  —   his prefe...\n",
       "2    Donald Trump is unabashedly praising Russian...\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4  From photography, illustration and video, to d..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Form Vector Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantial CV object\n",
    "# Words show up in a maximum of 90% of the documents in NPR\n",
    "# Words MUST show up in a minimum of 2 documents\n",
    "# Eliminate English stop-words\n",
    "cv = CountVectorizer(max_df=0.9,min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 54777)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document Term Matrix - fit transform to Article text in DataFrame\n",
    "# Number of articles by words\n",
    "dtm = cv.fit_transform(npr['Article'])\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LDA, form 8 Topics\n",
    "LDA = LatentDirichletAllocation(n_components=8,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=8, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to dtm (may take a while)\n",
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorize Articles into Topics\n",
    "\n",
    "cv --> contains vocabulary list of all words that were in all the documents<br />\n",
    "LDA.components_ --> 8 topics with array of 'probabilities' that a word exists in a specific topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accreditor'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of words in cv (picked 1500 index at random)\n",
    "cv.get_feature_names()[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 54777)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 Topics, with index positions of every word\n",
    "LDA.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21228, 36310, 18349, 31464, 10425,  8149, 36283, 22673, 42561,\n",
       "       42993])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array of index positions, ranked least to greatest\n",
    "# The greatest values are most likely to be related to the specified topic\n",
    "# Code below will give the 10 most likely records to be related to Topic '0' (defined as components_[0])\n",
    "top10 = LDA.components_[0].argsort()[-10:]\n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government\n",
      "percent\n",
      "federal\n",
      "million\n",
      "company\n",
      "care\n",
      "people\n",
      "health\n",
      "said\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "# Map the top 10 above for Topic 0 to English words\n",
    "# These words are clustered into Topic 0\n",
    "for i in top10:\n",
    "    print(cv.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 10 WORDS FOR TOPIC #0\n",
      "['government', 'percent', 'federal', 'million', 'company', 'care', 'people', 'health', 'said', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #1\n",
      "['new', 'security', 'obama', 'news', 'white', 'russia', 'house', 'president', 'said', 'trump']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #2\n",
      "['world', 'time', 'water', 'years', 'new', 'food', 'just', 'people', 'like', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #3\n",
      "['just', 'disease', 'patients', 'children', 'like', 'study', 'women', 'health', 'people', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #4\n",
      "['vote', 'party', 'republican', 'campaign', 'president', 'people', 'state', 'clinton', 'said', 'trump']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #5\n",
      "['new', 'way', 'music', 'really', 'time', 'know', 'think', 'people', 'just', 'like']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #6\n",
      "['time', 'schools', 'people', 'education', 'just', 'new', 'like', 'students', 'school', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #7\n",
      "['reported', 'government', 'according', 'city', 'told', 'reports', 'says', 'people', 'police', 'said']\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the top 10 words for each of the 8 topics\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f\"THE TOP 10 WORDS FOR TOPIC #{i}\")\n",
    "    print([cv.get_feature_names()[index] for index in topic.argsort()[-10:]])\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.9 , 0.  , 0.  , 0.08, 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array of percentage of probabilities that document belongs to a topic\n",
    "# We can see that the first document is most likely to be associated with Topic 1 at 90% (indexed at zero)\n",
    "topic_results = LDA.transform(dtm)\n",
    "topic_results[0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Topic\n",
       "0  In the Washington of 2016, even when the polic...      1\n",
       "1    Donald Trump has used Twitter  —   his prefe...      1\n",
       "2    Donald Trump is unabashedly praising Russian...      1\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...      1\n",
       "4  From photography, illustration and video, to d...      7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Topic number to NPR DataFrame to associate story with a Topic\n",
    "npr['Topic'] = topic_results.argmax(axis=1)\n",
    "npr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF\n",
    "\n",
    "Utilizing TF-IDF instead of CountVectorizer<br />\n",
    "Follows nearly the exact same pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantial TF-IDF object\n",
    "# Words show up in a maximum of 90% of the documents in NPR\n",
    "# Words MUST show up in a minimum of 2 documents\n",
    "# Eliminate English stop-words\n",
    "tfidf = TfidfVectorizer(max_df=0.95,min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 54777)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document Term Matrix - fit transform to Article text in DataFrame\n",
    "# Number of articles by words\n",
    "dtm = tfidf.fit_transform(npr['Article'])\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate NMF, form 8 Topics\n",
    "nmf_model = NMF(n_components=8,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=8, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "nmf_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorize Articles into Topics\n",
    "\n",
    "tfidf --> contains vocabulary list of all words that were in all the documents<br />\n",
    "nmf_model.components_ --> 8 topics with array of 'probabilities' that a word exists in a specific topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accreditor'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of words in tfidf (picked 1500 index at random)\n",
    "tfidf.get_feature_names()[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 54777)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 Topics, with index positions of every word\n",
    "nmf_model.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47218, 26752, 54412, 33390, 36310, 28659, 53152, 19307, 36283,\n",
       "       42993])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array of index positions, ranked least to greatest\n",
    "# The greatest values are most likely to be related to the specified topic\n",
    "# Code below will give the 10 most likely records to be related to Topic '0' (defined as components_[0])\n",
    "top10 = nmf_model.components_[0].argsort()[-10:]\n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study\n",
      "just\n",
      "years\n",
      "new\n",
      "percent\n",
      "like\n",
      "water\n",
      "food\n",
      "people\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "# Map the top 10 above for Topic 0 to English words\n",
    "# These words are clustered into Topic 0\n",
    "for i in top10:\n",
    "    print(tfidf.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 10 WORDS FOR TOPIC #0\n",
      "['study', 'just', 'years', 'new', 'percent', 'like', 'water', 'food', 'people', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #1\n",
      "['election', 'republican', 'obama', 'white', 'house', 'donald', 'campaign', 'said', 'president', 'trump']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #2\n",
      "['law', 'plan', 'republicans', 'affordable', 'obamacare', 'coverage', 'medicaid', 'insurance', 'care', 'health']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #3\n",
      "['state', 'law', 'isis', 'russia', 'president', 'attack', 'reports', 'court', 'said', 'police']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #4\n",
      "['party', 'delegates', 'vote', 'state', 'democratic', 'hillary', 'campaign', 'voters', 'sanders', 'clinton']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #5\n",
      "['album', 'life', 'song', 'really', 'people', 'know', 'think', 'just', 'music', 'like']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #6\n",
      "['devos', 'children', 'college', 'kids', 'teachers', 'student', 'education', 'schools', 'school', 'students']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 10 WORDS FOR TOPIC #7\n",
      "['pregnant', 'microcephaly', 'cases', 'mosquitoes', 'health', 'disease', 'mosquito', 'women', 'virus', 'zika']\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the top 10 words for each of the 8 topics\n",
    "for i,topic in enumerate(nmf_model.components_):\n",
    "    print(f\"THE TOP 10 WORDS FOR TOPIC #{i}\")\n",
    "    print([cv.get_feature_names()[index] for index in topic.argsort()[-10:]])\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.12, 0.  , 0.06, 0.02, 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array of percentage of probabilities that document belongs to a topic\n",
    "# We can see that the first document is most likely to be associated with Topic 1 at 12% (indexed at zero)\n",
    "topic_results = nmf_model.transform(dtm)\n",
    "topic_results[0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Topic\n",
       "0  In the Washington of 2016, even when the polic...      1\n",
       "1    Donald Trump has used Twitter  —   his prefe...      1\n",
       "2    Donald Trump is unabashedly praising Russian...      1\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...      3\n",
       "4  From photography, illustration and video, to d...      6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Topic number to NPR DataFrame to associate story with a Topic\n",
    "npr['Topic'] = topic_results.argmax(axis=1)\n",
    "npr.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_course]",
   "language": "python",
   "name": "conda-env-nlp_course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
